# ğŸ“¦ Required libraries
library(httr)
library(jsonlite)
library(glue)
library(fs)
library(DBI)

# ğŸ“¡ Dataset API
dataset_slug <- "chiffres-cles-de-ladem"
api_url <- glue("https://data.public.lu/api/1/datasets/{dataset_slug}/")

# ğŸ“ Create folder if not existing
dir_create("data/fetched")

# ğŸŒ Request API
res <- GET(api_url)
stop_for_status(res)
parsed <- fromJSON(content(res, "text", encoding = "UTF-8"))

# ğŸ¯ Filter CSV files
csv_files <- subset(parsed$resources, tolower(format) == "csv")

# ğŸ—„ï¸ Connect to PostgreSQL
source("scripts/connect_db.R")
con <- connect_db()

# ğŸ§  Create log table if needed
dbExecute(con, "
  CREATE TABLE IF NOT EXISTS student_ibtissam.etl_run_log (
    id SERIAL PRIMARY KEY,
    filename TEXT,
    download_date TIMESTAMP DEFAULT NOW(),
    status TEXT,
    message TEXT
  )
")

# ğŸ” Loop through CSV files
new_files_downloaded <- 0

for (i in seq_len(nrow(csv_files))) {
  titre <- csv_files$title[i]
  file_url <- csv_files$url[i]
  date <- as.Date(csv_files$last_modified[i])
  nom_fichier <- glue("data/fetched/{date}_{basename(file_url)}")
  
  if (!file_exists(nom_fichier)) {
    message("â¬‡ï¸ TÃ©lÃ©chargement : ", titre)
    tryCatch({
      download.file(file_url, nom_fichier, mode = "wb")
      dbExecute(con, "INSERT INTO student_ibtissam.etl_run_log (filename, status, message)
                      VALUES ($1, 'SUCCESS', $2)", params = list(nom_fichier, titre))
      new_files_downloaded <- new_files_downloaded + 1
    }, error = function(e) {
      dbExecute(con, "INSERT INTO student_ibtissam.etl_run_log (filename, status, message)
                      VALUES ($1, 'ERROR', $2)", params = list(nom_fichier, e$message))
      message("âŒ Ã‰chec : ", titre)
    })
  } else {
    message("âœ… DÃ©jÃ  tÃ©lÃ©chargÃ© : ", titre)
  }
}

# âœ… Final summary
message("ğŸ“¦ ", nrow(csv_files), " fichiers dÃ©tectÃ©s dans lâ€™API")
message("âœ… ", new_files_downloaded, " nouveaux fichiers tÃ©lÃ©chargÃ©s")

# ğŸ”Œ Disconnect from DB
dbDisconnect(con)
